#!/usr/bin/env python3

"""
EPUB XHTMLæ–‡ä»¶æ ¼å¼åŒ–å·¥å…·ï¼ˆæ”¯æŒæ–‡ä»¶åæ’åºå¤„ç†ï¼‰
åŠŸèƒ½ï¼š
1. æŒ‰æ–‡ä»¶åé¡ºåºå¤„ç†æ–‡ä»¶ï¼ˆä»å°åˆ°å¤§ï¼‰
2. æ ‡å‡†åŒ–å¤´éƒ¨å£°æ˜ï¼ˆXML + DOCTYPEï¼‰
3. ä¿®å¤è‡ªé—­åˆæ ‡ç­¾å¹¶ä¿æŒæ¢è¡Œ
4. 4ç©ºæ ¼ç¼©è¿›æ ¼å¼åŒ–
5. å°†h2-spanæ–‡æœ¬å¤åˆ¶åˆ°title
6. æ¸…ç†headéƒ¨åˆ†
"""
import os
import argparse
import re
from lxml import etree

# éœ€è¦ä¿ç•™æ¢è¡Œçš„è‡ªé—­åˆæ ‡ç­¾åˆ—è¡¨
LINE_PRESERVING_TAGS = {"p", "div", "span", "a", "ul", "li", "h1", "h2", "h3", "br"}

# æ ‡å‡†å¤´éƒ¨å£°æ˜
STANDARD_XML_DECLARATION = '<?xml version="1.0" encoding="UTF-8"?>'
STANDARD_DOCTYPE = '<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN" "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">'
STANDARD_HTML_ATTRS = 'xmlns="http://www.w3.org/1999/xhtml" xml:lang="zh-Hans"'

# XHTMLå‘½åç©ºé—´
XHTML_NS = "http://www.w3.org/1999/xhtml"

def extract_declarations(content):
    """åˆ†ç¦»XMLå£°æ˜å’ŒDOCTYPEå£°æ˜ï¼ˆä¿®å¤ç‰ˆï¼‰"""
    xml_declaration = ""
    doctype = ""
    body_start = 0
    
    # æŸ¥æ‰¾ç¬¬ä¸€ä¸ªæœ‰æ•ˆçš„XMLå£°æ˜ä½ç½®ï¼ˆå¿½ç•¥å‰é¢çš„éæ³•å†…å®¹ï¼‰
    xml_match = re.search(r'<\?xml[^>]*\?>', content)
    if xml_match:
        # ç§»é™¤å£°æ˜å‰æ‰€æœ‰å†…å®¹ï¼ˆåŒ…æ‹¬éæ³•æ ‡ç­¾ï¼‰
        body_start = xml_match.end()
        xml_declaration = xml_match.group(0).strip()
    
    # åœ¨XMLå£°æ˜åæŸ¥æ‰¾DOCTYPE
    if body_start > 0:
        remaining = content[body_start:]
    else:
        remaining = content
        
    doctype_match = re.search(r'<!DOCTYPE[^>]+>', remaining, re.IGNORECASE)
    if doctype_match:
        doctype = doctype_match.group(0).strip()
        body_start += doctype_match.end()
    
    return xml_declaration, doctype, content[body_start:].lstrip()

def format_self_closing_tags(content):
    """é¢„å¤„ç†ï¼šä¿ç•™ç‰¹å®šè‡ªé—­åˆæ ‡ç­¾çš„å•ç‹¬æ¢è¡Œç‰¹æ€§"""
    pattern = r'<([a-z]+:)?([a-z0-9]+)([^>]*)/>'
    
    def replace_tag(match):
        ns_prefix = match.group(1) or ""
        tag_name = match.group(2)
        attributes = match.group(3)
        
        if tag_name in LINE_PRESERVING_TAGS:
            start_pos = match.start()
            preceding_text = content[:start_pos]
            if "\n" in preceding_text:
                last_newline = preceding_text.rfind("\n")
                if not preceding_text[last_newline+1:start_pos].strip():
                    return f"<{ns_prefix}{tag_name}{attributes}></{ns_prefix}{tag_name}>"
        
        return match.group(0)
    
    return re.sub(pattern, replace_tag, content, flags=re.IGNORECASE)

def fix_self_closing_tags(root):
    """ä¿®å¤éç©ºå…ƒç´ çš„è‡ªé—­åˆæ ‡ç­¾"""
    non_void_elements = {"p", "div", "span", "a", "ul", "li", "h1", "h2", "h3"}
    
    for tag in root.iter():
        tag_name = tag.tag.split("}")[-1] if '}' in tag.tag else tag.tag
        if tag_name in non_void_elements and tag.text is None and len(tag) == 0:
            tag.text = ""

def standardize_html_tag(content):
    """ç¡®ä¿<html>æ ‡ç­¾åŒ…å«å¿…è¦çš„å±æ€§å’Œå€¼"""
    html_match = re.search(r'<html\b([^>]*)>', content, re.IGNORECASE)
    if not html_match:
        return content
    
    html_attrs = html_match.group(1)
    attrs_dict = {}
    
    # æå–ç°æœ‰å±æ€§
    for attr_match in re.finditer(r'(\w+)\s*=\s*["\']([^"\']*)["\']', html_attrs):
        attrs_dict[attr_match.group(1).lower()] = attr_match.group(2)
    
    # ç¡®ä¿å¿…è¦å±æ€§å­˜åœ¨
    if "xmlns" not in attrs_dict:
        attrs_dict["xmlns"] = "http://www.w3.org/1999/xhtml"
    if "xml:lang" not in attrs_dict:
        attrs_dict["xml:lang"] = "zh-Hans"
    
    # é‡å»º<html>æ ‡ç­¾
    new_attrs = ' '.join([f'{k}="{v}"' for k, v in attrs_dict.items()])
    new_html_tag = f'<html {new_attrs}>'
    
    return content.replace(html_match.group(0), new_html_tag)

def clean_head_section(root):
    """æ¸…ç†headéƒ¨åˆ†ï¼Œåªä¿ç•™titleå’Œstylesheeté“¾æ¥"""
    # æŸ¥æ‰¾headå…ƒç´ 
    head = root.find(f".//{{{XHTML_NS}}}head")
    if head is None:
        return
    
    # ä¿ç•™çš„å…ƒç´ åˆ—è¡¨
    elements_to_keep = []
    
    # æŸ¥æ‰¾ç°æœ‰çš„titleå…ƒç´ 
    title = head.find(f".//{{{XHTML_NS}}}title")
    if title is not None:
        elements_to_keep.append(title)
    
    # æŸ¥æ‰¾æ‰€æœ‰æ ·å¼è¡¨é“¾æ¥
    for link in head.findall(f".//{{{XHTML_NS}}}link"):
        rel_attr = link.get("rel", "").lower()
        if "stylesheet" in rel_attr:
            elements_to_keep.append(link)
    
    # æ¸…ç©ºheadå¹¶é‡æ–°æ·»åŠ è¦ä¿ç•™çš„å…ƒç´ 
    head.clear()
    for element in elements_to_keep:
        head.append(element)

def update_title_from_h2(root):
    """å°†h2-spanæ–‡æœ¬å¤åˆ¶åˆ°titleæ ‡ç­¾"""
    # æŸ¥æ‰¾headä¸­çš„titleå…ƒç´ 
    head = root.find(f".//{{{XHTML_NS}}}head")
    if head is None:
        return
    
    title = head.find(f".//{{{XHTML_NS}}}title")
    if title is None:
        title = etree.Element(f"{{{XHTML_NS}}}title")
        head.insert(0, title)
    
    # æŸ¥æ‰¾ç¬¬ä¸€ä¸ªh2å…ƒç´ 
    h2 = root.find(f".//{{{XHTML_NS}}}h2")
    if h2 is None:
        return
    
    # æŸ¥æ‰¾h2ä¸­çš„ç¬¬ä¸€ä¸ªspan
    span = h2.find(f".//{{{XHTML_NS}}}span")
    if span is not None and span.text:
        title.text = span.text.strip()
    elif h2.text:
        title.text = h2.text.strip()

def format_epub_xhtml_file(input_path, output_path, indent_size=4):
    """æ ¼å¼åŒ–EPUB XHTMLæ–‡ä»¶ï¼ˆä¿®å¤ç‰ˆï¼‰"""
    try:
        # æ–‡æœ¬æ¨¡å¼è¯»å–
        with open(input_path, 'r', encoding='utf-8') as f:
            raw_content = f.read()
        
        # æ ‡å‡†åŒ–<html>æ ‡ç­¾å±æ€§
        raw_content = standardize_html_tag(raw_content)
        
        # åˆ†ç¦»å£°æ˜ä¸ä¸»ä½“å†…å®¹
        xml_decl, doctype, body_content = extract_declarations(raw_content)
        
        # å¼ºåˆ¶ä½¿ç”¨æ ‡å‡†å£°æ˜
        xml_decl = STANDARD_XML_DECLARATION
        doctype = STANDARD_DOCTYPE
        
        # å¤„ç†è‡ªé—­åˆæ ‡ç­¾
        processed_body = format_self_closing_tags(body_content)
        
        # è§£æXMLä¸»ä½“
        parser = etree.XMLParser(
            remove_blank_text=True,
            resolve_entities=False,
            recover=True
        )
        
        # å°†å¤„ç†åçš„å†…å®¹ç¼–ç å›UTF-8
        processed_bytes = processed_body.encode('utf-8')
        root = etree.fromstring(processed_bytes, parser)
        
        # ä¿®å¤è‡ªé—­åˆæ ‡ç­¾
        fix_self_closing_tags(root)
        
        # æ¸…ç†headéƒ¨åˆ†
        clean_head_section(root)
        
        # æ›´æ–°titleå†…å®¹
        update_title_from_h2(root)
        
        # åº”ç”¨ç¼©è¿›
        etree.indent(root, space=" " * indent_size)
        
        # åºåˆ—åŒ–ä¸»ä½“
        formatted_body = etree.tostring(
            root,
            encoding="utf-8",
            xml_declaration=False,
            pretty_print=True,
            method="xml"
        ).decode('utf-8')
        
        # åå¤„ç†ï¼šæ¢å¤å•ç‹¬æˆè¡Œçš„ç©ºæ ‡ç­¾
        formatted_body = re.sub(
            r'<(/?)(p|div|span|a|ul|li|h1|h2|h3|br)([^>]*)>\s*</\2>',
            r'<\1\2\3></\2>', 
            formatted_body
        )
        
        # ç»„åˆæœ€ç»ˆå†…å®¹
        full_content = f"{xml_decl}\n{doctype}\n{formatted_body}"
        
        # æ–‡æœ¬æ¨¡å¼å†™å…¥
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write(full_content)
            
        return True, None
        
    except Exception as e:
        return False, f"è§£æå¤±è´¥: {str(e)}"

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description='EPUB XHTMLæ–‡ä»¶æ‰¹é‡æ ¼å¼åŒ–ï¼ˆæŒ‰æ–‡ä»¶åæ’åºï¼‰')
    parser.add_argument('source_dir', help='æºæ–‡ä»¶ç›®å½•')
    parser.add_argument('--indent', type=int, default=4, help='ç¼©è¿›ç©ºæ ¼æ•°ï¼ˆé»˜è®¤4ï¼‰')
    args = parser.parse_args()
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    source_dir = os.path.abspath(args.source_dir)
    base_name = os.path.basename(source_dir)
    parent_dir = os.path.dirname(source_dir)
    output_dir = os.path.join(parent_dir, f"{base_name}_formatted")
    os.makedirs(output_dir, exist_ok=True)
    
    print(f"ğŸ” æ‰«æç›®å½•: {source_dir}")
    print(f"ğŸ“‚ è¾“å‡ºç›®å½•: {output_dir}")
    errors = []
    
    # è·å–æ‰€æœ‰XHTMLæ–‡ä»¶ï¼ˆä¿ç•™åŸå§‹æ‰©å±•åï¼‰
    file_list = []
    for filename in os.listdir(source_dir):
        if filename.lower().endswith(('.xhtml', '.html', '.xml')):
            file_list.append(filename)
    
    # æŒ‰æ–‡ä»¶åè‡ªç„¶æ’åº
    file_list.sort(key=lambda f: [int(s) if s.isdigit() else s.lower() for s in re.split(r'(\d+)', f)])
    
    print(f"ğŸ“Š æ‰¾åˆ° {len(file_list)} ä¸ªæ–‡ä»¶ï¼ŒæŒ‰æ–‡ä»¶åæ’åºå¤„ç†...")
    
    for filename in file_list:
        input_file = os.path.join(source_dir, filename)
        # ä¿æŒåŸå§‹æ–‡ä»¶æ‰©å±•å
        output_file = os.path.join(output_dir, filename)
        
        success, error = format_epub_xhtml_file(input_file, output_file, args.indent)
        
        if success:
            print(f"âœ… æˆåŠŸ: {filename}")
        else:
            print(f"âŒ å¤±è´¥: {filename} - {error}")
            errors.append(filename)
    
    print(f"\nğŸ‰ å®Œæˆï¼å¤„ç†æ–‡ä»¶: {len(file_list) - len(errors)}/{len(file_list)} ä¸ª")
    if errors:
        print(f"âš ï¸ å¤±è´¥æ–‡ä»¶: {', '.join(errors)}")